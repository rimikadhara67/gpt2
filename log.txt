Trying to keep track of all the runtimes with different configurations and optimizations

This log/notes section is in the opposite chronological order for my convenience. So, the most recent logs appear frist. 
All of these were run on 1 A100 available in Colab Notebook

# ----- OPTIMIZATION #4 ----- 
Flash-Attention
B = 8 ; T = 1024 ; dtype = tensorfloat32
-----------------------------

--------------------------------------------------------------------------------

# ----- OPTIMIZATION #3 ----- 
Using torch.compile : gcc of neural networks
B = 8 ; T = 1024 ; dtype = tensorfloat32
-----------------------------
--> makes compilation a bit slow but the computations are a lot faster
    it aims to reduce pytorch overhead and reduce gpu reads and writes
--> insane speedup and throughput
--> analyze the entire thing to get a sense before hand of what you want to do 
    it has a bird's eye view of your entire code and knows exactly what computations you're going to need and when
    it optimizes that process to run in efficient code -- i think this is like jit
--> now that it knows which computations are when -- it makes the element-wise computations while the data is written on the gpu 
    this is also called kernel fusion -- it fuses a bunch of operations together to happen during one roundtrip that the data is making
    kind of checks like "oh i have this piece of data, are there any more computations that need to happen here?"
-----------------------------
cuda
loaded 338025 tokens
1 Epoch = 41 batches
step 1: loss = 10.977867126464844 | time = 89.90073204040527 | throughput = 91.12272852592747
step 2: loss = 9.502176284790039 | time = 81.44664764404297 | throughput = 100.5811808952847
step 3: loss = 9.041337966918945 | time = 77.70490646362305 | throughput = 105.42448827005566
step 4: loss = 8.3361177444458 | time = 78.31120491027832 | throughput = 104.60827424869315
step 5: loss = 7.98040246963501 | time = 78.35197448730469 | throughput = 104.55384249860026
step 6: loss = 7.541772365570068 | time = 78.32121849060059 | throughput = 104.59489979695772
step 7: loss = 7.143893241882324 | time = 78.3078670501709 | throughput = 104.6127331593834
step 8: loss = 6.843379020690918 | time = 78.3846378326416 | throughput = 104.51027428985093
step 9: loss = 6.602263450622559 | time = 77.73804664611816 | throughput = 105.37954519608535
step 10: loss = 6.396775245666504 | time = 77.81124114990234 | throughput = 105.28041808532804
step 11: loss = 6.22437047958374 | time = 78.32670211791992 | throughput = 104.58757714153522
step 12: loss = 6.0895466804504395 | time = 77.86059379577637 | throughput = 105.21368513431995
step 13: loss = 5.995548248291016 | time = 77.87966728210449 | throughput = 105.18791728174719
step 14: loss = 5.940192699432373 | time = 78.61208915710449 | throughput = 104.20789076891815
step 15: loss = 5.912414073944092 | time = 78.36794853210449 | throughput = 104.53253088083626
step 16: loss = 5.8999223709106445 | time = 78.43232154846191 | throughput = 104.44673622134609
step 17: loss = 5.894169807434082 | time = 78.6292552947998 | throughput = 104.18514036901712
step 18: loss = 5.888120174407959 | time = 78.48906517028809 | throughput = 104.37122651705462
step 19: loss = 5.880875587463379 | time = 77.80218124389648 | throughput = 105.29267777621152
step 20: loss = 5.873743057250977 | time = 78.02414894104004 | throughput = 104.99313496120786
step 21: loss = 5.866426944732666 | time = 77.64911651611328 | throughput = 105.50023448496088
step 22: loss = 5.864376068115234 | time = 77.62742042541504 | throughput = 105.52972074952471
step 23: loss = 5.8614501953125 | time = 77.81791687011719 | throughput = 105.27138645555038
step 24: loss = 5.860881805419922 | time = 78.43184471130371 | throughput = 104.44737121960561
step 25: loss = 5.860180854797363 | time = 78.35102081298828 | throughput = 104.5551151088769
step 26: loss = 5.864166259765625 | time = 78.54008674621582 | throughput = 104.30342439613746
step 27: loss = 5.871365070343018 | time = 78.34291458129883 | throughput = 104.56593354717371
step 28: loss = 5.866133689880371 | time = 78.30119132995605 | throughput = 104.62165212122319
step 29: loss = 5.857914924621582 | time = 77.9731273651123 | throughput = 105.06183703060454
step 30: loss = 5.849363327026367 | time = 77.82793045043945 | throughput = 105.25784191597688
step 31: loss = 5.843747138977051 | time = 77.81195640563965 | throughput = 105.27945033658428
step 32: loss = 5.839478492736816 | time = 77.88896560668945 | throughput = 105.17536002938566
step 33: loss = 5.836612701416016 | time = 77.88300514221191 | throughput = 105.183409205149
step 34: loss = 5.8363800048828125 | time = 78.05132865905762 | throughput = 104.95657333117472
step 35: loss = 5.837681293487549 | time = 78.42278480529785 | throughput = 104.45943765371858
step 36: loss = 5.840752601623535 | time = 78.3388614654541 | throughput = 104.57134360591277
step 37: loss = 5.84300422668457 | time = 78.27925682067871 | throughput = 104.650967992276
step 38: loss = 5.84693717956543 | time = 78.31835746765137 | throughput = 104.59872071989795
step 39: loss = 5.847560882568359 | time = 78.03678512573242 | throughput = 104.9761338425346
step 40: loss = 5.847979545593262 | time = 77.7578353881836 | throughput = 105.35272695161586
step 41: loss = 5.849864959716797 | time = 78.03702354431152 | throughput = 104.97581311963239
step 42: loss = 5.847596168518066 | time = 78.15337181091309 | throughput = 104.81953382408122
step 43: loss = 5.847255706787109 | time = 78.34672927856445 | throughput = 104.56084223851983
step 44: loss = 5.846600532531738 | time = 78.54509353637695 | throughput = 104.29677566309093
step 45: loss = 5.8443708419799805 | time = 78.3090591430664 | throughput = 104.6111406476441
step 46: loss = 5.844832420349121 | time = 78.56106758117676 | throughput = 104.27556870373799
step 47: loss = 5.84435510635376 | time = 78.60231399536133 | throughput = 104.22085029816611
step 48: loss = 5.845335960388184 | time = 78.31931114196777 | throughput = 104.59744704790027
step 49: loss = 5.8457417488098145 | time = 78.2926082611084 | throughput = 104.63312159277429
step 50: loss = 5.846532821655273 | time = 78.45473289489746 | throughput = 104.41690001002847
--------------------------------------------------------------------------------

# ----- OPTIMIZATION #2 ----- 
Precision change to BF16 to save memory -- using torch.autocast
B = 8 ; T = 1024 ; dtype = tensorfloat32
--> not a lot faster but oh well
-----------------------------
cuda
loaded 338025 tokens
1 Epoch = 41 batches
step 1: loss = 10.999964714050293 | time = 214.4143581390381 | throughput = 38.20639658230283
step 2: loss = 9.49085521697998 | time = 205.1551342010498 | throughput = 39.93075792084213
step 3: loss = 8.866656303405762 | time = 203.86695861816406 | throughput = 40.18306868129298
step 4: loss = 8.420998573303223 | time = 203.7515640258789 | throughput = 40.20582634133555
step 5: loss = 8.000720977783203 | time = 203.76825332641602 | throughput = 40.20253334987001
step 6: loss = 7.5556440353393555 | time = 204.1482925415039 | throughput = 40.127692953075
step 7: loss = 7.171408176422119 | time = 203.4461498260498 | throughput = 40.266183493786
step 8: loss = 6.865958213806152 | time = 203.871488571167 | throughput = 40.18217582759423
step 9: loss = 6.613677978515625 | time = 203.82189750671387 | throughput = 40.19195238691248
step 10: loss = 6.396533966064453 | time = 203.81522178649902 | throughput = 40.193268825531106
step 11: loss = 6.2149128913879395 | time = 203.6752700805664 | throughput = 40.22088688901479
step 12: loss = 6.077444553375244 | time = 203.88555526733398 | throughput = 40.179403534785386
step 13: loss = 5.990556716918945 | time = 203.86195182800293 | throughput = 40.18405556575628
step 14: loss = 5.943273544311523 | time = 203.72271537780762 | throughput = 40.211519784663096
step 15: loss = 5.919780254364014 | time = 203.40657234191895 | throughput = 40.27401821721645
step 16: loss = 5.910135746002197 | time = 203.77635955810547 | throughput = 40.20093409149409
step 17: loss = 5.9018144607543945 | time = 203.78994941711426 | throughput = 40.198253267302874
step 18: loss = 5.891624450683594 | time = 203.77683639526367 | throughput = 40.200840021434374
step 19: loss = 5.880627155303955 | time = 203.3541202545166 | throughput = 40.284406284696615
step 20: loss = 5.870386123657227 | time = 203.89366149902344 | throughput = 40.17780611605347
step 21: loss = 5.865752696990967 | time = 203.66311073303223 | throughput = 40.22328820626884
step 22: loss = 5.861918926239014 | time = 203.7336826324463 | throughput = 40.209355145163194
step 23: loss = 5.859808921813965 | time = 203.70912551879883 | throughput = 40.214202378695205
step 24: loss = 5.8578925132751465 | time = 203.76014709472656 | throughput = 40.20413273549317
step 25: loss = 5.858131408691406 | time = 203.91392707824707 | throughput = 40.173813124870655
step 26: loss = 5.863741874694824 | time = 204.96249198913574 | throughput = 39.96828844388868
step 27: loss = 5.870166301727295 | time = 203.6440372467041 | throughput = 40.22705555614094
step 28: loss = 5.869153022766113 | time = 203.91321182250977 | throughput = 40.17395404045955
step 29: loss = 5.861891269683838 | time = 203.5973072052002 | throughput = 40.236288546505705
step 30: loss = 5.853564262390137 | time = 203.37319374084473 | throughput = 40.28062818563462
step 31: loss = 5.847261905670166 | time = 203.66287231445312 | throughput = 40.22333529378711
step 32: loss = 5.8431010246276855 | time = 203.7646770477295 | throughput = 40.20323894548769
step 33: loss = 5.839210033416748 | time = 203.627347946167 | throughput = 40.23035256622662
step 34: loss = 5.838056564331055 | time = 203.64141464233398 | throughput = 40.227573621937545
step 35: loss = 5.838972091674805 | time = 203.37390899658203 | throughput = 40.28048652070545
step 36: loss = 5.840801239013672 | time = 203.77635955810547 | throughput = 40.20093409149409
step 37: loss = 5.842396259307861 | time = 203.8893699645996 | throughput = 40.17865179250071
step 38: loss = 5.845513343811035 | time = 203.7339210510254 | throughput = 40.20930809037099
step 39: loss = 5.846497535705566 | time = 203.53341102600098 | throughput = 40.24892010950226
step 40: loss = 5.849394798278809 | time = 203.6113739013672 | throughput = 40.23350878211914
step 41: loss = 5.850845813751221 | time = 203.74131202697754 | throughput = 40.20784944643574
step 42: loss = 5.849950313568115 | time = 203.40847969055176 | throughput = 40.273640570258465
step 43: loss = 5.850064277648926 | time = 203.33504676818848 | throughput = 40.288185092554485
step 44: loss = 5.846957206726074 | time = 203.78518104553223 | throughput = 40.19919386665138
step 45: loss = 5.845311164855957 | time = 203.69362831115723 | throughput = 40.21726191398637
step 46: loss = 5.845368385314941 | time = 203.69577407836914 | throughput = 40.21683825825587
step 47: loss = 5.844884395599365 | time = 203.55510711669922 | throughput = 40.24463014481618
step 48: loss = 5.846238613128662 | time = 203.67670059204102 | throughput = 40.220604399952244
step 49: loss = 5.846622467041016 | time = 203.6271095275879 | throughput = 40.23039967028618
step 50: loss = 5.846555233001709 | time = 203.39035987854004 | throughput = 40.27722850233448

--------------------------------------------------------------------------------

# ----- OPTIMIZATION #1 ----- 
Precision change to TF32 to save memory 
B = 8 ; T = 1024 ; dtype = tensorfloat32
-----------------------------
cuda
loaded 338025 tokens
1 Epoch = 41 batches
step 1: loss = 11.006056785583496 | time = 255.3417682647705 | throughput = 32.08249106940273
step 2: loss = 9.612740516662598 | time = 238.3575439453125 | throughput = 34.36853671339863
step 3: loss = 11.051552772521973 | time = 237.16211318969727 | throughput = 34.541773514420996
step 4: loss = 8.475252151489258 | time = 237.12611198425293 | throughput = 34.54701775122941
step 5: loss = 7.484814167022705 | time = 236.8175983428955 | throughput = 34.59202380786984
step 6: loss = 6.813332557678223 | time = 237.26272583007812 | throughput = 34.52712587423831
step 7: loss = 6.363587379455566 | time = 237.22124099731445 | throughput = 34.53316391719214
step 8: loss = 6.100831031799316 | time = 236.98759078979492 | throughput = 34.567210767023674
step 9: loss = 5.985622406005859 | time = 237.1804714202881 | throughput = 34.53909991385264
step 10: loss = 5.935225963592529 | time = 237.20741271972656 | throughput = 34.535177067502914
step 11: loss = 5.9066386222839355 | time = 237.0607852935791 | throughput = 34.5565378510618
step 12: loss = 5.899106502532959 | time = 236.9084358215332 | throughput = 34.578760235330584
step 13: loss = 5.909369945526123 | time = 237.1687889099121 | throughput = 34.54080124814276
step 14: loss = 5.923038005828857 | time = 237.02430725097656 | throughput = 34.56185610248735
step 15: loss = 5.920040130615234 | time = 236.7711067199707 | throughput = 34.5988161878581
step 16: loss = 5.896843433380127 | time = 237.12539672851562 | throughput = 34.54712195749747
step 17: loss = 5.863986968994141 | time = 237.1819019317627 | throughput = 34.53889159872257
step 18: loss = 5.831890106201172 | time = 236.88268661499023 | throughput = 34.58251895510881
step 19: loss = 5.820229530334473 | time = 237.1540069580078 | throughput = 34.54295419706121
step 20: loss = 5.827034950256348 | time = 237.17164993286133 | throughput = 34.540384579350004
step 21: loss = 5.837375164031982 | time = 237.09964752197266 | throughput = 34.55087380187196
step 22: loss = 5.84666109085083 | time = 236.87195777893066 | throughput = 34.58408532953268
step 23: loss = 5.84515380859375 | time = 237.1504306793213 | throughput = 34.54347511212137
step 24: loss = 5.835930347442627 | time = 237.0767593383789 | throughput = 34.55420945883432
step 25: loss = 5.825813293457031 | time = 236.95802688598633 | throughput = 34.5715235210902
step 26: loss = 5.818314075469971 | time = 237.10083961486816 | throughput = 34.550700087382964
step 27: loss = 5.814695835113525 | time = 237.18833923339844 | throughput = 34.53795421173254
step 28: loss = 5.812010765075684 | time = 236.83834075927734 | throughput = 34.588994221701434
step 29: loss = 5.812100410461426 | time = 237.23983764648438 | throughput = 34.530456947146696
step 30: loss = 5.810514450073242 | time = 237.17117309570312 | throughput = 34.54045402345069
step 31: loss = 5.807673454284668 | time = 237.1068000793457 | throughput = 34.54983154113935
step 32: loss = 5.805992126464844 | time = 237.08701133728027 | throughput = 34.55271528285474
step 33: loss = 5.802384853363037 | time = 237.59698867797852 | throughput = 34.47855145631847
step 34: loss = 5.798579216003418 | time = 237.14828491210938 | throughput = 34.543787668698826
step 35: loss = 5.794641494750977 | time = 237.2605800628662 | throughput = 34.527438135021804
step 36: loss = 5.789761066436768 | time = 237.24365234375 | throughput = 34.529901723694366
step 37: loss = 5.783792495727539 | time = 237.26749420166016 | throughput = 34.526431981607196
step 38: loss = 5.767065525054932 | time = 237.2124195098877 | throughput = 34.53444814114606
step 39: loss = 7.053713321685791 | time = 237.6255989074707 | throughput = 34.47440022314217
step 40: loss = 5.803648471832275 | time = 237.14685440063477 | throughput = 34.54399604289279
step 41: loss = 5.827505588531494 | time = 237.2722625732422 | throughput = 34.52573811686589
step 42: loss = 5.841487884521484 | time = 237.10942268371582 | throughput = 34.54944939462589
step 43: loss = 5.84422492980957 | time = 237.29228973388672 | throughput = 34.52282418947106
step 44: loss = 5.841358184814453 | time = 237.2746467590332 | throughput = 34.525391194953386
step 45: loss = 5.8339314460754395 | time = 237.29777336120605 | throughput = 34.52202641417303
step 46: loss = 5.825125217437744 | time = 237.54143714904785 | throughput = 34.48661462319875
step 47: loss = 5.816109657287598 | time = 237.0901107788086 | throughput = 34.5522635806715
step 48: loss = 5.810768127441406 | time = 237.17713356018066 | throughput = 34.539585992261706
step 49: loss = 5.809289932250977 | time = 236.87458038330078 | throughput = 34.58370242490368
step 50: loss = 5.809300899505615 | time = 237.19239234924316 | throughput = 34.537364031212526

--------------------------------------------------------------

# ----- BASELINE CHANGE ----- #
changing the baseline metric from time to throughput and batch to 8
B = 8 ; T = 1024 ; dtype = float32
-------------------------------
cuda
loaded 338025 tokens
1 Epoch = 41 batches
step 1: loss = 11.029096603393555 | time = 955.348014831543 | throughput = 8.574885667653268
step 2: loss = 9.574460983276367 | time = 577.4695873260498 | throughput = 14.186028458975187
step 3: loss = 8.52872085571289 | time = 577.6572227478027 | throughput = 14.181420533499528
step 4: loss = 7.646514892578125 | time = 577.7809619903564 | throughput = 14.178383399445982
step 5: loss = 7.036017417907715 | time = 577.7089595794678 | throughput = 14.180150513786753
step 6: loss = 6.524392127990723 | time = 577.6762962341309 | throughput = 14.180952296993334
step 7: loss = 6.202227592468262 | time = 577.7175426483154 | throughput = 14.179939841270954
step 8: loss = 6.019207000732422 | time = 577.674150466919 | throughput = 14.181004972056687
step 9: loss = 5.93194580078125 | time = 577.7349472045898 | throughput = 14.179512663441175
step 10: loss = 5.901697635650635 | time = 577.6910781860352 | throughput = 14.180589434967718
step 11: loss = 5.901927471160889 | time = 577.4860382080078 | throughput = 14.185624340668959
step 12: loss = 5.911057472229004 | time = 577.6858329772949 | throughput = 14.180718190335082
step 13: loss = 5.917102336883545 | time = 577.5485038757324 | throughput = 14.184090072134655
step 14: loss = 5.908847808837891 | time = 577.6937007904053 | throughput = 14.180525058160818
step 15: loss = 5.887024879455566 | time = 577.71897315979 | throughput = 14.179904729793584
step 16: loss = 5.86067533493042 | time = 577.6348114013672 | throughput = 14.181970750907224
step 17: loss = 5.839723587036133 | time = 577.6126384735107 | throughput = 14.182515156956152
step 18: loss = 5.82953405380249 | time = 577.6290893554688 | throughput = 14.182111238789608
step 19: loss = 5.8264312744140625 | time = 577.6517391204834 | throughput = 14.181555157217934
step 20: loss = 5.831329345703125 | time = 577.6374340057373 | throughput = 14.18190636155799
step 21: loss = 5.835185527801514 | time = 577.7146816253662 | throughput = 14.180010064747343
step 22: loss = 5.834731578826904 | time = 577.6903629302979 | throughput = 14.180606992380136
step 23: loss = 5.829263210296631 | time = 577.6104927062988 | throughput = 14.182567843630633
step 24: loss = 5.820180416107178 | time = 577.6731967926025 | throughput = 14.181028383321564
step 25: loss = 5.812677383422852 | time = 577.5022506713867 | throughput = 14.185226101675322
step 26: loss = 5.806911945343018 | time = 577.6028633117676 | throughput = 14.182755177199107
step 27: loss = 5.803328037261963 | time = 577.6698589324951 | throughput = 14.181110323357366
step 28: loss = 5.801115036010742 | time = 577.669620513916 | throughput = 14.181116176253301
step 29: loss = 5.7981367111206055 | time = 577.6259899139404 | throughput = 14.182187337554726
step 30: loss = 5.794368743896484 | time = 577.6870250701904 | throughput = 14.18068892754628
step 31: loss = 5.789984703063965 | time = 577.6476860046387 | throughput = 14.181654663348233
step 32: loss = 5.784980297088623 | time = 577.6004791259766 | throughput = 14.182813719954165
step 33: loss = 5.777536392211914 | time = 577.6736736297607 | throughput = 14.181016677679462
step 34: loss = 5.77039909362793 | time = 577.725887298584 | throughput = 14.17973502677085
step 35: loss = 5.763670921325684 | time = 577.7254104614258 | throughput = 14.179746730297182
step 36: loss = 5.755492687225342 | time = 577.6631832122803 | throughput = 14.181274206269773
step 37: loss = 5.744278430938721 | time = 577.7754783630371 | throughput = 14.17851796550748
step 38: loss = 5.728265762329102 | time = 577.8274536132812 | throughput = 14.177242615894476
step 39: loss = 5.693336486816406 | time = 577.6300430297852 | throughput = 14.182087823949255
step 40: loss = 5.645940780639648 | time = 577.587366104126 | throughput = 14.183135713746147
step 41: loss = 5.64841890335083 | time = 577.5902271270752 | throughput = 14.183065459308203
step 42: loss = 5.587576866149902 | time = 577.613353729248 | throughput = 14.182497594818313
step 43: loss = 5.5731658935546875 | time = 577.5179862976074 | throughput = 14.184839596975749
step 44: loss = 5.557539463043213 | time = 577.5907039642334 | throughput = 14.183053750302879
step 45: loss = 5.607537269592285 | time = 577.6212215423584 | throughput = 14.182304414172672
step 46: loss = 5.561897277832031 | time = 578.0611038208008 | throughput = 14.17151222570326
step 47: loss = 5.5241289138793945 | time = 577.5480270385742 | throughput = 14.184101782851142
step 48: loss = 5.522468566894531 | time = 577.6445865631104 | throughput = 14.181730757213607
step 49: loss = 5.507747650146484 | time = 577.556848526001 | throughput = 14.183885137726326
step 50: loss = 5.5220417976379395 | time = 577.6791572570801 | throughput = 14.180882064184251

--------------------------------------------------------------

# ----- BASELINE ----- #
B = 4 ; T = 1024 ; dtype = float32
------------------------
cuda
loaded 338025 tokens
1 Epoch = 82 batches
step 1: loss = 10.957832336425781 | time = 1589.1225337982178
step 2: loss = 9.744239807128906 | time = 1212.7771377563477
step 3: loss = 10.972354888916016 | time = 1230.9072017669678
step 4: loss = 8.774917602539062 | time = 1239.363670349121
step 5: loss = 7.651184558868408 | time = 1245.945692062378
step 6: loss = 6.87078857421875 | time = 1245.624303817749
step 7: loss = 6.329787731170654 | time = 1244.5142269134521
step 8: loss = 5.989801406860352 | time = 1257.246732711792
step 9: loss = 5.809932708740234 | time = 1256.6657066345215
step 10: loss = 5.739829063415527 | time = 1226.353645324707
step 11: loss = 5.726529121398926 | time = 1253.2141208648682
step 12: loss = 5.719888210296631 | time = 1255.2611827850342
step 13: loss = 5.71586799621582 | time = 1259.6900463104248
step 14: loss = 5.716298580169678 | time = 1260.7014179229736
step 15: loss = 5.709798336029053 | time = 1262.582778930664
step 16: loss = 5.691406726837158 | time = 1268.1748867034912
step 17: loss = 5.663188934326172 | time = 1268.4566974639893
step 18: loss = 5.636880397796631 | time = 1274.1649150848389
step 19: loss = 5.62070369720459 | time = 1275.9020328521729
step 20: loss = 5.6150031089782715 | time = 1272.2272872924805
step 21: loss = 5.619780540466309 | time = 1278.289794921875
step 22: loss = 5.62244987487793 | time = 1282.4633121490479
step 23: loss = 5.624851226806641 | time = 1289.5894050598145
step 24: loss = 5.618223190307617 | time = 1285.5684757232666
step 25: loss = 5.6100335121154785 | time = 1292.560338973999
step 26: loss = 5.600595474243164 | time = 1295.4905033111572
step 27: loss = 5.593338489532471 | time = 1298.9661693572998
step 28: loss = 5.587722301483154 | time = 1300.8184432983398
step 29: loss = 5.583390235900879 | time = 1293.1113243103027
step 30: loss = 5.575660705566406 | time = 1317.1510696411133
step 31: loss = 5.555104732513428 | time = 1307.7375888824463
step 32: loss = 5.494010925292969 | time = 1326.1082172393799
step 33: loss = 9.473379135131836 | time = 1327.1868228912354
step 34: loss = 5.924776077270508 | time = 1316.1354064941406
step 35: loss = 5.6139702796936035 | time = 1333.8656425476074
step 36: loss = 5.634500026702881 | time = 1317.8064823150635
step 37: loss = 5.63551139831543 | time = 1329.9860954284668
step 38: loss = 5.626481056213379 | time = 1320.6093311309814
step 39: loss = 5.609877109527588 | time = 1344.2010879516602
step 40: loss = 5.600749969482422 | time = 1335.1902961730957
step 41: loss = 5.597568511962891 | time = 1331.3891887664795
step 42: loss = 5.602120876312256 | time = 1336.2674713134766
step 43: loss = 5.612254619598389 | time = 1345.306634902954
step 44: loss = 5.614740371704102 | time = 1340.6474590301514
step 45: loss = 5.608066082000732 | time = 1354.4979095458984
step 46: loss = 5.599985599517822 | time = 1372.894048690796
step 47: loss = 5.594512939453125 | time = 1378.643274307251
step 48: loss = 5.5951409339904785 | time = 1382.4083805084229
step 49: loss = 5.598855972290039 | time = 1357.0613861083984
step 50: loss = 5.6001200675964355 | time = 1364.9451732635498

--------------------------------------------------------------

