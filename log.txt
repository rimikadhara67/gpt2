Trying to keep track of all the runtimes with different configurations and optimizations

This log/notes section is in the opposite chronological order for my convenience. So, the most recent logs appear frist. 
All of these were run on 1 A100 available in Colab Notebook

# ----- OPTIMIZATION #2 ----- 
Precision change to BF16 to save memory 
B = 8 ; T = 1024 ; dtype = tensorfloat32
-----------------------------
cuda
loaded 338025 tokens
1 Epoch = 41 batches
step 1: loss = 10.973641395568848 | time = 243.1645393371582 | throughput = 33.68912269169904
step 2: loss = 9.511648178100586 | time = 237.64300346374512 | throughput = 34.471875378606605
step 3: loss = 11.267569541931152 | time = 237.46180534362793 | throughput = 34.49817956258465
step 4: loss = 8.398275375366211 | time = 237.43820190429688 | throughput = 34.5016089841428
step 5: loss = 7.479693412780762 | time = 237.3514175415039 | throughput = 34.51422403477967
step 6: loss = 6.8221306800842285 | time = 237.43414878845215 | throughput = 34.50219794330792
step 7: loss = 6.375897407531738 | time = 237.900972366333 | throughput = 34.43449565807368
step 8: loss = 6.120739459991455 | time = 237.3824119567871 | throughput = 34.50971760069261
step 9: loss = 6.010340690612793 | time = 237.2910976409912 | throughput = 34.52299762376278
step 10: loss = 5.961503028869629 | time = 237.48254776000977 | throughput = 34.495166391252056
step 11: loss = 5.930331707000732 | time = 237.39337921142578 | throughput = 34.508123298182184
step 12: loss = 5.916490077972412 | time = 237.3063564300537 | throughput = 34.5207777964203
step 13: loss = 5.9230122566223145 | time = 237.4579906463623 | throughput = 34.4987337663446
step 14: loss = 5.929091930389404 | time = 237.45131492614746 | throughput = 34.49970366577204
step 15: loss = 5.920347213745117 | time = 237.16020584106445 | throughput = 34.542051314839725
step 16: loss = 5.895249843597412 | time = 237.45965957641602 | throughput = 34.49849130000864
step 17: loss = 5.8666534423828125 | time = 237.3650074005127 | throughput = 34.5122479918761
step 18: loss = 5.842788219451904 | time = 237.12611198425293 | throughput = 34.54701775122941
step 19: loss = 5.833892822265625 | time = 237.08391189575195 | throughput = 34.553166996848354
step 20: loss = 5.831587314605713 | time = 237.24365234375 | throughput = 34.529901723694366
step 21: loss = 5.838578224182129 | time = 237.30182647705078 | throughput = 34.52143677786753
step 22: loss = 5.843734264373779 | time = 237.0772361755371 | throughput = 34.55413995941165
step 23: loss = 5.844045162200928 | time = 237.31493949890137 | throughput = 34.51952926898613
step 24: loss = 5.837421894073486 | time = 237.29658126831055 | throughput = 34.522199840449154
step 25: loss = 5.826012134552002 | time = 236.8485927581787 | throughput = 34.58749703598194
step 26: loss = 5.81509256362915 | time = 237.2605800628662 | throughput = 34.527438135021804
step 27: loss = 5.806216239929199 | time = 237.2572422027588 | throughput = 34.52792388524503
step 28: loss = 5.802340507507324 | time = 237.1535301208496 | throughput = 34.543023651494835
step 29: loss = 5.80009651184082 | time = 237.10346221923828 | throughput = 34.550317921655854
step 30: loss = 5.799042224884033 | time = 237.33115196228027 | throughput = 34.51717118577834
step 31: loss = 5.79671573638916 | time = 237.2584342956543 | throughput = 34.527750401453474
step 32: loss = 5.785717964172363 | time = 236.89842224121094 | throughput = 34.58022186259591
step 33: loss = 5.767972469329834 | time = 237.213134765625 | throughput = 34.53434401132124
step 34: loss = 10.626351356506348 | time = 237.0617389678955 | throughput = 34.55639883376295
step 35: loss = 5.794473171234131 | time = 236.91868782043457 | throughput = 34.57726393541771
step 36: loss = 5.821693420410156 | time = 237.67924308776855 | throughput = 34.46661935461867
step 37: loss = 5.835241794586182 | time = 237.23673820495605 | throughput = 34.53090807934934
step 38: loss = 5.83563756942749 | time = 237.04004287719727 | throughput = 34.55956175406199
step 39: loss = 5.825725078582764 | time = 236.85741424560547 | throughput = 34.58620886363911
step 40: loss = 5.815871238708496 | time = 237.31017112731934 | throughput = 34.52022288418859
step 41: loss = 5.809816360473633 | time = 237.28036880493164 | throughput = 34.524558610808
step 42: loss = 5.809730529785156 | time = 237.11323738098145 | throughput = 34.54889356024233
step 43: loss = 5.816171646118164 | time = 237.20240592956543 | throughput = 34.53590602463164
step 44: loss = 5.818800926208496 | time = 237.24126815795898 | throughput = 34.53024873625965
step 45: loss = 5.819301128387451 | time = 237.0290756225586 | throughput = 34.561160813219445
step 46: loss = 5.814115047454834 | time = 237.14685440063477 | throughput = 34.54399604289279
step 47: loss = 5.809423446655273 | time = 237.26844787597656 | throughput = 34.52629320642781
step 48: loss = 5.808419227600098 | time = 237.27726936340332 | throughput = 34.52500958890207
step 49: loss = 5.808386325836182 | time = 237.2450828552246 | throughput = 34.52969351950299
step 50: loss = 5.80863094329834 | time = 237.1807098388672 | throughput = 34.539065194489794
--------------------------------------------------------------------------------

# ----- OPTIMIZATION #1 ----- 
Precision change to TF32 to save memory 
B = 8 ; T = 1024 ; dtype = tensorfloat32
-----------------------------
cuda
loaded 338025 tokens
1 Epoch = 41 batches
step 1: loss = 11.006056785583496 | time = 255.3417682647705 | throughput = 32.08249106940273
step 2: loss = 9.612740516662598 | time = 238.3575439453125 | throughput = 34.36853671339863
step 3: loss = 11.051552772521973 | time = 237.16211318969727 | throughput = 34.541773514420996
step 4: loss = 8.475252151489258 | time = 237.12611198425293 | throughput = 34.54701775122941
step 5: loss = 7.484814167022705 | time = 236.8175983428955 | throughput = 34.59202380786984
step 6: loss = 6.813332557678223 | time = 237.26272583007812 | throughput = 34.52712587423831
step 7: loss = 6.363587379455566 | time = 237.22124099731445 | throughput = 34.53316391719214
step 8: loss = 6.100831031799316 | time = 236.98759078979492 | throughput = 34.567210767023674
step 9: loss = 5.985622406005859 | time = 237.1804714202881 | throughput = 34.53909991385264
step 10: loss = 5.935225963592529 | time = 237.20741271972656 | throughput = 34.535177067502914
step 11: loss = 5.9066386222839355 | time = 237.0607852935791 | throughput = 34.5565378510618
step 12: loss = 5.899106502532959 | time = 236.9084358215332 | throughput = 34.578760235330584
step 13: loss = 5.909369945526123 | time = 237.1687889099121 | throughput = 34.54080124814276
step 14: loss = 5.923038005828857 | time = 237.02430725097656 | throughput = 34.56185610248735
step 15: loss = 5.920040130615234 | time = 236.7711067199707 | throughput = 34.5988161878581
step 16: loss = 5.896843433380127 | time = 237.12539672851562 | throughput = 34.54712195749747
step 17: loss = 5.863986968994141 | time = 237.1819019317627 | throughput = 34.53889159872257
step 18: loss = 5.831890106201172 | time = 236.88268661499023 | throughput = 34.58251895510881
step 19: loss = 5.820229530334473 | time = 237.1540069580078 | throughput = 34.54295419706121
step 20: loss = 5.827034950256348 | time = 237.17164993286133 | throughput = 34.540384579350004
step 21: loss = 5.837375164031982 | time = 237.09964752197266 | throughput = 34.55087380187196
step 22: loss = 5.84666109085083 | time = 236.87195777893066 | throughput = 34.58408532953268
step 23: loss = 5.84515380859375 | time = 237.1504306793213 | throughput = 34.54347511212137
step 24: loss = 5.835930347442627 | time = 237.0767593383789 | throughput = 34.55420945883432
step 25: loss = 5.825813293457031 | time = 236.95802688598633 | throughput = 34.5715235210902
step 26: loss = 5.818314075469971 | time = 237.10083961486816 | throughput = 34.550700087382964
step 27: loss = 5.814695835113525 | time = 237.18833923339844 | throughput = 34.53795421173254
step 28: loss = 5.812010765075684 | time = 236.83834075927734 | throughput = 34.588994221701434
step 29: loss = 5.812100410461426 | time = 237.23983764648438 | throughput = 34.530456947146696
step 30: loss = 5.810514450073242 | time = 237.17117309570312 | throughput = 34.54045402345069
step 31: loss = 5.807673454284668 | time = 237.1068000793457 | throughput = 34.54983154113935
step 32: loss = 5.805992126464844 | time = 237.08701133728027 | throughput = 34.55271528285474
step 33: loss = 5.802384853363037 | time = 237.59698867797852 | throughput = 34.47855145631847
step 34: loss = 5.798579216003418 | time = 237.14828491210938 | throughput = 34.543787668698826
step 35: loss = 5.794641494750977 | time = 237.2605800628662 | throughput = 34.527438135021804
step 36: loss = 5.789761066436768 | time = 237.24365234375 | throughput = 34.529901723694366
step 37: loss = 5.783792495727539 | time = 237.26749420166016 | throughput = 34.526431981607196
step 38: loss = 5.767065525054932 | time = 237.2124195098877 | throughput = 34.53444814114606
step 39: loss = 7.053713321685791 | time = 237.6255989074707 | throughput = 34.47440022314217
step 40: loss = 5.803648471832275 | time = 237.14685440063477 | throughput = 34.54399604289279
step 41: loss = 5.827505588531494 | time = 237.2722625732422 | throughput = 34.52573811686589
step 42: loss = 5.841487884521484 | time = 237.10942268371582 | throughput = 34.54944939462589
step 43: loss = 5.84422492980957 | time = 237.29228973388672 | throughput = 34.52282418947106
step 44: loss = 5.841358184814453 | time = 237.2746467590332 | throughput = 34.525391194953386
step 45: loss = 5.8339314460754395 | time = 237.29777336120605 | throughput = 34.52202641417303
step 46: loss = 5.825125217437744 | time = 237.54143714904785 | throughput = 34.48661462319875
step 47: loss = 5.816109657287598 | time = 237.0901107788086 | throughput = 34.5522635806715
step 48: loss = 5.810768127441406 | time = 237.17713356018066 | throughput = 34.539585992261706
step 49: loss = 5.809289932250977 | time = 236.87458038330078 | throughput = 34.58370242490368
step 50: loss = 5.809300899505615 | time = 237.19239234924316 | throughput = 34.537364031212526

--------------------------------------------------------------

# ----- BASELINE CHANGE ----- #
changing the baseline metric from time to throughput and batch to 8
B = 8 ; T = 1024 ; dtype = float32
-------------------------------
cuda
loaded 338025 tokens
1 Epoch = 41 batches
step 1: loss = 11.029096603393555 | time = 955.348014831543 | throughput = 8.574885667653268
step 2: loss = 9.574460983276367 | time = 577.4695873260498 | throughput = 14.186028458975187
step 3: loss = 8.52872085571289 | time = 577.6572227478027 | throughput = 14.181420533499528
step 4: loss = 7.646514892578125 | time = 577.7809619903564 | throughput = 14.178383399445982
step 5: loss = 7.036017417907715 | time = 577.7089595794678 | throughput = 14.180150513786753
step 6: loss = 6.524392127990723 | time = 577.6762962341309 | throughput = 14.180952296993334
step 7: loss = 6.202227592468262 | time = 577.7175426483154 | throughput = 14.179939841270954
step 8: loss = 6.019207000732422 | time = 577.674150466919 | throughput = 14.181004972056687
step 9: loss = 5.93194580078125 | time = 577.7349472045898 | throughput = 14.179512663441175
step 10: loss = 5.901697635650635 | time = 577.6910781860352 | throughput = 14.180589434967718
step 11: loss = 5.901927471160889 | time = 577.4860382080078 | throughput = 14.185624340668959
step 12: loss = 5.911057472229004 | time = 577.6858329772949 | throughput = 14.180718190335082
step 13: loss = 5.917102336883545 | time = 577.5485038757324 | throughput = 14.184090072134655
step 14: loss = 5.908847808837891 | time = 577.6937007904053 | throughput = 14.180525058160818
step 15: loss = 5.887024879455566 | time = 577.71897315979 | throughput = 14.179904729793584
step 16: loss = 5.86067533493042 | time = 577.6348114013672 | throughput = 14.181970750907224
step 17: loss = 5.839723587036133 | time = 577.6126384735107 | throughput = 14.182515156956152
step 18: loss = 5.82953405380249 | time = 577.6290893554688 | throughput = 14.182111238789608
step 19: loss = 5.8264312744140625 | time = 577.6517391204834 | throughput = 14.181555157217934
step 20: loss = 5.831329345703125 | time = 577.6374340057373 | throughput = 14.18190636155799
step 21: loss = 5.835185527801514 | time = 577.7146816253662 | throughput = 14.180010064747343
step 22: loss = 5.834731578826904 | time = 577.6903629302979 | throughput = 14.180606992380136
step 23: loss = 5.829263210296631 | time = 577.6104927062988 | throughput = 14.182567843630633
step 24: loss = 5.820180416107178 | time = 577.6731967926025 | throughput = 14.181028383321564
step 25: loss = 5.812677383422852 | time = 577.5022506713867 | throughput = 14.185226101675322
step 26: loss = 5.806911945343018 | time = 577.6028633117676 | throughput = 14.182755177199107
step 27: loss = 5.803328037261963 | time = 577.6698589324951 | throughput = 14.181110323357366
step 28: loss = 5.801115036010742 | time = 577.669620513916 | throughput = 14.181116176253301
step 29: loss = 5.7981367111206055 | time = 577.6259899139404 | throughput = 14.182187337554726
step 30: loss = 5.794368743896484 | time = 577.6870250701904 | throughput = 14.18068892754628
step 31: loss = 5.789984703063965 | time = 577.6476860046387 | throughput = 14.181654663348233
step 32: loss = 5.784980297088623 | time = 577.6004791259766 | throughput = 14.182813719954165
step 33: loss = 5.777536392211914 | time = 577.6736736297607 | throughput = 14.181016677679462
step 34: loss = 5.77039909362793 | time = 577.725887298584 | throughput = 14.17973502677085
step 35: loss = 5.763670921325684 | time = 577.7254104614258 | throughput = 14.179746730297182
step 36: loss = 5.755492687225342 | time = 577.6631832122803 | throughput = 14.181274206269773
step 37: loss = 5.744278430938721 | time = 577.7754783630371 | throughput = 14.17851796550748
step 38: loss = 5.728265762329102 | time = 577.8274536132812 | throughput = 14.177242615894476
step 39: loss = 5.693336486816406 | time = 577.6300430297852 | throughput = 14.182087823949255
step 40: loss = 5.645940780639648 | time = 577.587366104126 | throughput = 14.183135713746147
step 41: loss = 5.64841890335083 | time = 577.5902271270752 | throughput = 14.183065459308203
step 42: loss = 5.587576866149902 | time = 577.613353729248 | throughput = 14.182497594818313
step 43: loss = 5.5731658935546875 | time = 577.5179862976074 | throughput = 14.184839596975749
step 44: loss = 5.557539463043213 | time = 577.5907039642334 | throughput = 14.183053750302879
step 45: loss = 5.607537269592285 | time = 577.6212215423584 | throughput = 14.182304414172672
step 46: loss = 5.561897277832031 | time = 578.0611038208008 | throughput = 14.17151222570326
step 47: loss = 5.5241289138793945 | time = 577.5480270385742 | throughput = 14.184101782851142
step 48: loss = 5.522468566894531 | time = 577.6445865631104 | throughput = 14.181730757213607
step 49: loss = 5.507747650146484 | time = 577.556848526001 | throughput = 14.183885137726326
step 50: loss = 5.5220417976379395 | time = 577.6791572570801 | throughput = 14.180882064184251

--------------------------------------------------------------

# ----- BASELINE ----- #
B = 4 ; T = 1024 ; dtype = float32
------------------------
cuda
loaded 338025 tokens
1 Epoch = 82 batches
step 1: loss = 10.957832336425781 | time = 1589.1225337982178
step 2: loss = 9.744239807128906 | time = 1212.7771377563477
step 3: loss = 10.972354888916016 | time = 1230.9072017669678
step 4: loss = 8.774917602539062 | time = 1239.363670349121
step 5: loss = 7.651184558868408 | time = 1245.945692062378
step 6: loss = 6.87078857421875 | time = 1245.624303817749
step 7: loss = 6.329787731170654 | time = 1244.5142269134521
step 8: loss = 5.989801406860352 | time = 1257.246732711792
step 9: loss = 5.809932708740234 | time = 1256.6657066345215
step 10: loss = 5.739829063415527 | time = 1226.353645324707
step 11: loss = 5.726529121398926 | time = 1253.2141208648682
step 12: loss = 5.719888210296631 | time = 1255.2611827850342
step 13: loss = 5.71586799621582 | time = 1259.6900463104248
step 14: loss = 5.716298580169678 | time = 1260.7014179229736
step 15: loss = 5.709798336029053 | time = 1262.582778930664
step 16: loss = 5.691406726837158 | time = 1268.1748867034912
step 17: loss = 5.663188934326172 | time = 1268.4566974639893
step 18: loss = 5.636880397796631 | time = 1274.1649150848389
step 19: loss = 5.62070369720459 | time = 1275.9020328521729
step 20: loss = 5.6150031089782715 | time = 1272.2272872924805
step 21: loss = 5.619780540466309 | time = 1278.289794921875
step 22: loss = 5.62244987487793 | time = 1282.4633121490479
step 23: loss = 5.624851226806641 | time = 1289.5894050598145
step 24: loss = 5.618223190307617 | time = 1285.5684757232666
step 25: loss = 5.6100335121154785 | time = 1292.560338973999
step 26: loss = 5.600595474243164 | time = 1295.4905033111572
step 27: loss = 5.593338489532471 | time = 1298.9661693572998
step 28: loss = 5.587722301483154 | time = 1300.8184432983398
step 29: loss = 5.583390235900879 | time = 1293.1113243103027
step 30: loss = 5.575660705566406 | time = 1317.1510696411133
step 31: loss = 5.555104732513428 | time = 1307.7375888824463
step 32: loss = 5.494010925292969 | time = 1326.1082172393799
step 33: loss = 9.473379135131836 | time = 1327.1868228912354
step 34: loss = 5.924776077270508 | time = 1316.1354064941406
step 35: loss = 5.6139702796936035 | time = 1333.8656425476074
step 36: loss = 5.634500026702881 | time = 1317.8064823150635
step 37: loss = 5.63551139831543 | time = 1329.9860954284668
step 38: loss = 5.626481056213379 | time = 1320.6093311309814
step 39: loss = 5.609877109527588 | time = 1344.2010879516602
step 40: loss = 5.600749969482422 | time = 1335.1902961730957
step 41: loss = 5.597568511962891 | time = 1331.3891887664795
step 42: loss = 5.602120876312256 | time = 1336.2674713134766
step 43: loss = 5.612254619598389 | time = 1345.306634902954
step 44: loss = 5.614740371704102 | time = 1340.6474590301514
step 45: loss = 5.608066082000732 | time = 1354.4979095458984
step 46: loss = 5.599985599517822 | time = 1372.894048690796
step 47: loss = 5.594512939453125 | time = 1378.643274307251
step 48: loss = 5.5951409339904785 | time = 1382.4083805084229
step 49: loss = 5.598855972290039 | time = 1357.0613861083984
step 50: loss = 5.6001200675964355 | time = 1364.9451732635498

--------------------------------------------------------------

