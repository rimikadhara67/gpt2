# GPT-2 + Some Optimizations
Planning on writing it from scratch in Pytorch and flax and comparing how they react to different optimizations!

Everything relevant is in:
- pytorch2-gpt2.py
- flax-gpt2.py

All my code was run in the colab notebooks but they have random sanity checks and graphs for testing/debugging:
- pytorch-gpt2.ipynb
- flax-gpt2.ipynb

All necessary logs and comparison data for each implementation can be found in:
- pytorch-logs.txt
- flax-logs.txt